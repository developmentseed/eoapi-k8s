comment_install: >
  `service` and `gitSha` are required and defaulted value keys.
  a manual installation looks like this:

  $ export GITSHA=$(git rev-parse HEAD | cut -c1-10)
  $ helm install \
      --namespace eoapi \
      --create-namespace \
      --set gitSha=$GITSHA \
      eoapi \
      ./eoapi

# the chart on the gh-pages branch will provide
# the correct updated value otherwise it's defaulted
gitSha: "gitshaABC123"


######################
# TESTING
######################
# only used in CI for running parallel helm installs
testing: false

#######################
# SERVICE ACCOUNT
#######################
serviceAccount:
  create: true
  name: ""
  automount: true
  annotations: {}
  labels: {}


######################
# SERVICE & INGRESS
######################
service:
  port: 8080

ingress:
  # `"nginx"` will create a `kind:Service` with a `spec.port:ClusterIP`
  # and a single Load Balancer and path rewrites for /vector, /stac, /raster
  enabled: true
  className: "nginx"
  host: ""
  tls:
    enabled: false
    secretName: eoapi-tls
    certManager: false
    certManagerIssuer: letsencrypt-prod
    certManagerEmail: ""


######################
# DATABASE
######################
comment_db: >
  We use the crunchydata postgres operator/cluster charts as the k8s internal HA solution for eoapi.
  Those charts are therefore listed as a dependency of this chart in `Chart.yaml`.

  0. make sure to install the operator first `helm install --set disable_check_for_upgrades=true pgo oci://registry.developers.crunchydata.com/crunchydata/pgo`
  1. it will create a postgres cluster: see `postgrescluster.instances` spec below
  2. will will also create user credentials and mount their secrets: see `postgrescluster.users` spec below

  The `postgrescluster` specs below are pass-through values to configure those separate
  charts. For more information read https://access.crunchydata.com/documentation/postgres-operator/latest

# DEPRECATED: this is the backward compatible way we originally did things
# and a temporary solution for EOEPCA. Since disabled by default most people SHOULD NOT
# use this option as it won't be talked about explicitly in the docs
db:
  enabled: false
  image:
    name: ghcr.io/stac-utils/pgstac
    tag: v0.9.5
  command:
    - "postgres"
    - "-N"
    - "500"
  # toggle to true||false if you want the db test fixtures loaded
  enable_data_fixtures: true
  storageClassName: ""
  accessModes:
    - ReadWriteOnce
  settings:
    resources:
      requests:
        storage: "100Mi"
        cpu: "512m"
        memory: "1024Mi"
      limits:
        cpu: "512m"
        memory: "1024Mi"
    secrets:
      POSTGRES_DB: "postgis"
      POSTGRES_USER: ""
      POSTGRES_PASSWORD: ""
      POSTGRES_PORT: "5432"
      POSTGRES_HOST: "pgstac"
      POSTGRES_HOST_READER: "pgstac"
      POSTGRES_HOST_WRITER: "pgstac"
      DB_MIN_CONN_SIZE: "1"
      DB_MAX_CONN_SIZE: "15"
      # default connect: https://www.postgresql.org/docs/current/libpq-envars.html
      PGDATA: "/data/pgdata"
      PGUSER: ""
      PGPASSWORD: ""
      PGDATABASE: "postgis"

# This section is used to configure a postgres cluster using the
# crunchydata postgres operator included in the `postgrescluster` chart.
# this is declared as a dependency of eoapi in helm-chart/eoapi/Chart.yaml
postgrescluster:
  enabled: true
  postgresVersion: 16
  postGISVersion: 3.4
  pgBouncerReplicas: 1
  monitoring: false
  instances:
  - name: eoapi
    replicas: 1
    dataVolumeClaimSpec:
      accessModes:
      - "ReadWriteOnce"
      resources:
        requests:
          storage: "10Gi"
          cpu: "1024m"
          memory: "3048Mi"
  # https://access.crunchydata.com/documentation/postgres-operator/latest/architecture/user-management
  users:
    # `postgres` always is a `SUPERUSER` and cannot be adjusted with `options` flag
    # we use this block here to create secrets for the `postgres` user that we can mount and lookup
    - name: postgres
      databases:
        - eoapi
        - postgres
    # if you try to grant `options: 'SUPERUSER'` below to your eoapi service user
    # then they will not be able to connect through the pgbouncer connection pooler, so be aware
    # https://access.crunchydata.com/documentation/crunchy-postgres-containers/2.4.2/container-specifications/crunchy-pgbouncer/
    # this user is currently unprivileged and the `pgstacBootstrap` container below will grant privileges
    # when it boots via the `postgres` superuser above.
    # see `/helm-chart/eoapi/templates/pgstacbootstrap/configmap.yaml:initdb-sh-config`
    - name: eoapi
      databases:
        - eoapi
        - postgres
      # default `password.type` is ASCII which follows the character set US-ASCII
      # but which can contain characters that `asyncpg` dislikes
      # see https://github.com/MagicStack/asyncpg/issues/1151
      password:
        type: AlphaNumeric

# `pgstacBootstrap` is a pod that by default runs pgstac schema migrations
# and optionally loads some fixtures for testing and examples
# using the LOAD_FIXTURES env var below
pgstacBootstrap:
  enabled: true
  image:
    name: ghcr.io/stac-utils/pgstac
    tag: v0.9.5
  command:
    - "sh"
  args:
    - "/opt/initdb/run-migrate-and-load.sh"
  settings:
    labels: {}
    resources:
      requests:
        cpu: "512m"
        memory: "1024Mi"
      limits:
        cpu: "512m"
        memory: "1024Mi"
    # TODO: to be deprecated in favor of `pgstacBootstrap.settings.extraEnvVars`
    # LOAD_FIXTURES and KEEP_ALIVE should be plain settings if this is a function of the chart
    envVars:
      # toggle to "false" if you don't want fixtures default loaded
      LOAD_FIXTURES: "true"
      # toggle to `true` if you want to keep the job running as db jumpbox
      KEEP_ALIVE: "false"
    # extra env vars to set in the pgstacBootstrap pod
    extraEnvVars: []
    # extra env var from mounts to set in the pgstacBootstrap pod
    extraEnvFrom: []
    # extra volumes to mount in the pgstacBootstrap pod
    extraVolumeMounts: []
    # extra volumes to mount in the pgstacBootstrap pod
    extraVolumes: []
    


######################
# API SERVICES
######################
apiServices:
  - raster
  - multidim
  - stac
  - vector

raster:
  enabled: true
  autoscaling:
    # NOTE: to have autoscaling working you'll need to install the `eoapi-support` chart
    # see ../../../docs/autoscaling.md for more information
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    # `type`: "cpu" || "requestRate" || "both"
    type: "requestRate"
    behaviour:
      scaleDown:
        stabilizationWindowSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
    targets:
      # matches `type` value above unless `type: "both"` is selected
      cpu: 75
      # 'm' units here represents generic milli (one-thousandth) unit instead of 'decimal'
      # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#quantities
      # so when the average unit among these pods is <requestRate>/1000 then scale
      # you can watch the actual/target in real time using `kubectl get hpa/<name>`
      requestRate: 100000m
  image:
    name: ghcr.io/stac-utils/titiler-pgstac
    tag: 1.7.1
  command:
    - "uvicorn"
    - "titiler.pgstac.main:app"
    - "--host=$(HOST)"
    - "--port=$(PORT)"
  settings:
    # Additional labels to add to the pod
    labels: {}
    # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    resources:
      limits:
        cpu: "768m"
        memory: "4096Mi"
      requests:
        cpu: "256m"
        memory: "3072Mi"
    # Additional environment variables from references like ConfigMap or Secret
    extraEnvFrom: []
    # Additional volume mounts
    extraVolumeMounts: []
    # Additional volumes
    extraVolumes: []
    envVars:
      ##############
      # titiler
      ##############
      GDAL_CACHEMAX: "200"  # 200 mb
      GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
      GDAL_INGESTED_BYTES_AT_OPEN: "32768"
      GDAL_HTTP_MERGE_CONSECUTIVE_RANGES: "YES"
      GDAL_HTTP_MULTIPLEX: "YES"
      GDAL_HTTP_VERSION: "2"
      PYTHONWARNINGS: "ignore"
      VSI_CACHE: "TRUE"
      VSI_CACHE_SIZE: "5000000"  # 5 MB (per file-handle)
      ##############
      # uvicorn
      ##############
      HOST: "0.0.0.0"
      PORT: "8080"
      # https://www.uvicorn.org/settings/#production
      WEB_CONCURRENCY: "5"
    # Additional environment variables
    extraEnvVars: []

multidim:
  enabled: false # disabled by default
  autoscaling:
    # NOTE: to have autoscaling working you'll need to install the `eoapi-support` chart
    # see ../../../docs/autoscaling.md for more information
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    # `type`: "cpu" || "requestRate" || "both"
    type: "requestRate"
    behaviour:
      scaleDown:
        stabilizationWindowSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
    targets:
      # matches `type` value above unless `type: "both"` is selected
      cpu: 75
      # 'm' units here represents generic milli (one-thousandth) unit instead of 'decimal'
      # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#quantities
      # so when the average unit among these pods is <requestRate>/1000 then scale
      # you can watch the actual/target in real time using `kubectl get hpa/<name>`
      requestRate: 100000m
  image:
    name: ghcr.io/developmentseed/titiler-md-demo
    tag: dd740a700ce655e785c7bd50331f9ac857be4126
  command:
    - "uvicorn"
    - "titiler_md_demo.main:app"
    - "--host=$(HOST)"
    - "--port=$(PORT)"
  settings:
    # Additional labels to add to the pod
    labels: {}
    # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    resources:
      limits:
        cpu: "768m"
        memory: "4096Mi"
      requests:
        cpu: "256m"
        memory: "3072Mi"
    # Additional environment variables from references like ConfigMap or Secret
    extraEnvFrom: []
    # Additional volume mounts
    extraVolumeMounts: []
    # Additional volumes
    extraVolumes: []
    envVars:
      ##############
      # titiler
      ##############
      GDAL_CACHEMAX: "200"  # 200 mb
      GDAL_DISABLE_READDIR_ON_OPEN: "EMPTY_DIR"
      GDAL_INGESTED_BYTES_AT_OPEN: "32768"
      GDAL_HTTP_MERGE_CONSECUTIVE_RANGES: "YES"
      GDAL_HTTP_MULTIPLEX: "YES"
      GDAL_HTTP_VERSION: "2"
      PYTHONWARNINGS: "ignore"
      VSI_CACHE: "TRUE"
      VSI_CACHE_SIZE: "5000000"  # 5 MB (per file-handle)
      ##############
      # uvicorn
      ##############
      HOST: "0.0.0.0"
      PORT: "8080"
      # https://www.uvicorn.org/settings/#production
      WEB_CONCURRENCY: "5"
    # Additional environment variables
    extraEnvVars: []

stac:
  enabled: true
  autoscaling:
    # NOTE: to have autoscaling working you'll need to install the `eoapi-support` chart
    # see ../../../docs/autoscaling.md for more information
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    # `type`: "cpu" || "requestRate" || "both"
    type: "requestRate"
    behaviour:
      scaleDown:
        stabilizationWindowSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
    targets:
      # matches `type` value above unless `type: "both"` is selected
      cpu: 75
      # 'm' units here represents generic milli (one-thousandth) unit instead of 'decimal'
      # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#quantities
      # so when the average unit among these pods is <requestRate>/1000 then scale
      # you can watch the actual/target in real time using `kubectl get hpa/<name>`
      requestRate: 100000m
  image:
    name: ghcr.io/stac-utils/stac-fastapi-pgstac
    tag: 5.0.1
  command:
    - "uvicorn"
    - "stac_fastapi.pgstac.app:app"
    - "--host=$(HOST)"
    - "--port=$(PORT)"
  settings:
    # Additional labels to add to the pod
    labels: {}
    # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    resources:
      limits:
        cpu: "768m"
        memory: "1024Mi"
      requests:
        cpu: "256m"
        memory: "1024Mi"
    # Additional environment variables from references like ConfigMap or Secret
    extraEnvFrom: []
    # Additional volume mounts
    extraVolumeMounts: []
    # Additional volumes
    extraVolumes: []
    envVars:
      ##############
      # uvicorn
      ##############
      HOST: "0.0.0.0"
      PORT: "8080"
      # https://www.uvicorn.org/settings/#production
      WEB_CONCURRENCY: "5"
      DB_MIN_CONN_SIZE: "1"
    # Additional environment variables
    extraEnvVars: []

vector:
  enabled: true
  autoscaling:
    # NOTE: to have autoscaling working you'll need to install the `eoapi-support` chart
    # see ../../../docs/autoscaling.md for more information
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    # `type`: "cpu" || "requestRate" || "both"
    type: "requestRate"
    behaviour:
      scaleDown:
        stabilizationWindowSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
    targets:
      # matches `type` value above unless `type: "both"` is selected
      cpu: 75
      # 'm' units here represents generic milli (one-thousandth) unit instead of 'decimal'
      # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#quantities
      # so when the average unit among these pods is <requestRate>/1000 then scale
      # you can watch the actual/target in real time using `kubectl get hpa/<name>`
      requestRate: 100000m
  image:
    name: ghcr.io/developmentseed/tipg
    tag: 1.0.1
  command:
    - "uvicorn"
    - "tipg.main:app"
    - "--host=$(HOST)"
    - "--port=$(PORT)"
  settings:
    # Additional labels to add to the pod
    labels: {}
    # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    resources:
      limits:
        cpu: "768m"
        memory: "1024Mi"
      requests:
        cpu: "256m"
        memory: "256Mi"
    # Additional environment variables from references like ConfigMap or Secret
    extraEnvFrom: []
    # Additional volume mounts
    extraVolumeMounts: []
    # Additional volumes
    extraVolumes: []
    envVars:
      ##############
      # tipg
      ##############
      TIPG_CATALOG_TTL: "300"
      TIPG_DEBUG: "True"
      ##############
      # uvicorn
      ##############
      HOST: "0.0.0.0"
      PORT: "8080"
      # https://www.uvicorn.org/settings/#production
      WEB_CONCURRENCY: "5"
    # Additional environment variables
    extraEnvVars: []

docServer:
  enabled: true
